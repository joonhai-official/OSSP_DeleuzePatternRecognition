{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 설치 (가벼운 조합: openai, gradio, plotly만)\n",
        "!pip -q install --upgrade --force-reinstall \"httpx==0.27.2\" \"openai==1.51.0\"\n",
        "!pip -q install --upgrade \"gradio==4.44.0\" \"plotly==5.24.1\"\n",
        "\n",
        "# 이미 로드된 모듈 제거(Colab 잔존 모듈 충돌 방지)\n",
        "import sys\n",
        "for m in [\"httpx\", \"openai\"]:\n",
        "    if m in sys.modules:\n",
        "        del sys.modules[m]\n",
        "\n",
        "import httpx, openai\n",
        "print(\"httpx:\", httpx.__version__)\n",
        "print(\"openai:\", openai.__version__)\n",
        "print(\"✅ install ok\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd19geR0Xv9t",
        "outputId": "80b50b11-c796-4ba1-ebf5-d09aed82838c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.3 requires websockets>=14.0, but you have websockets 12.0 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "google-adk 1.11.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 12.0 which is incompatible.\n",
            "google-genai 1.30.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "google-genai 1.30.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mhttpx: 0.28.1\n",
            "openai: 1.51.0\n",
            "✅ install ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기능 중심 유틸: 공통 상수/간단 함수\n",
        "import os, re, time, socket, textwrap, traceback\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# 긴 응답을 세그먼트로 이어붙이는 파라미터(사실상 길이 제한 완화)\n",
        "LONG_SEGMENT_TOKENS = 1500\n",
        "LONG_MAX_SEGMENTS   = 12\n",
        "\n",
        "def md(s: str) -> str:\n",
        "    return textwrap.dedent(s).strip()\n",
        "\n",
        "def find_free_port(start=7860, end=7950) -> int:\n",
        "    for p in range(start, end+1):\n",
        "        try:\n",
        "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "                s.settimeout(0.1)\n",
        "                if s.connect_ex((\"127.0.0.1\", p)) != 0:\n",
        "                    return p\n",
        "        except:\n",
        "            pass\n",
        "    raise OSError(\"No free port\")\n"
      ],
      "metadata": {
        "id": "okEtpAbZXv7b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성은 OpenAI API만 사용. httpx Client를 직접 주입해서 proxies 충돌 경로 차단.\n",
        "import httpx\n",
        "from openai import OpenAI\n",
        "\n",
        "_HTTPX = httpx.Client(timeout=httpx.Timeout(60.0, connect=30.0, read=60.0))\n",
        "\n",
        "def _openai_client() -> OpenAI:\n",
        "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "        raise RuntimeError(\"OPENAI_API_KEY가 없습니다. 상단 UI에서 저장하세요.\")\n",
        "    # 핵심: http_client=_HTTPX 주입\n",
        "    return OpenAI(http_client=_HTTPX)\n",
        "\n",
        "def _openai_chat(system, user, model, temperature, top_p, max_tokens):\n",
        "    client = _openai_client()\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\":\"system\",\"content\":system},{\"role\":\"user\",\"content\":user}],\n",
        "        temperature=float(temperature), top_p=float(top_p), max_tokens=int(max_tokens),\n",
        "    )\n",
        "    return (resp.choices[0].message.content or \"\").strip()\n",
        "\n",
        "def llm_once(system, user, model_id, temperature, top_p, max_tokens):\n",
        "    return _openai_chat(system, user, model_id, temperature, top_p, max_tokens)\n",
        "\n",
        "def llm_long(system, user, model_id, temperature=0.7, top_p=0.9,\n",
        "             segment_tokens=LONG_SEGMENT_TOKENS, max_segments=LONG_MAX_SEGMENTS, stop_marker=\"[END]\"):\n",
        "    out = []\n",
        "    prompt = user + \"\\n\\n(문서가 길면 여러 번 나눠 작성. 완전히 끝나면 마지막 줄에 [END])\"\n",
        "    for _ in range(max_segments):\n",
        "        seg = llm_once(system, prompt, model_id, temperature, top_p, segment_tokens)\n",
        "        seg = (seg or \"\").strip()\n",
        "        out.append(seg)\n",
        "        if stop_marker in seg:\n",
        "            break\n",
        "        prompt = \"이어서 계속. 반복 없이 자연스럽게 연결. 끝나면 [END].\"\n",
        "    return \"\\n\".join(out).replace(stop_marker, \"\").strip()\n",
        "\n",
        "print(\"✅ LLM 엔진 준비 완료 (OpenAI + httpx 주입)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMZOWQ6UXv5T",
        "outputId": "9b11ffb7-0a39-4a96-d93b-be203363e910"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LLM 엔진 준비 완료 (OpenAI + httpx 주입)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A) 순정 GPT — 문단형(비교 기준)\n",
        "BASELINE_SYSTEM = \"\"\"You are a helpful assistant.\n",
        "Write the answer in Korean as plain paragraphs only.\n",
        "Do NOT use headings, lists, tables, math, code blocks, KPIs, or IF–THEN rules.\n",
        "No hard limit on length; write comprehensively.\n",
        "\"\"\"\n",
        "BASELINE_USER_TPL = \"Question:\\n{q}\\n\\n(Write only plain paragraphs. No explicit structure.)\"\n",
        "\n",
        "# B) 들뢰즈 오퍼레이터 — 6개 섹션 강제 + 표/수식 포함\n",
        "DELEUZE_SYSTEM = md(\"\"\"\n",
        "You are a Deleuzian policy designer.\n",
        "Always output ALL the following SECTIONS in Korean with the exact headings:\n",
        "\n",
        "### 문제-이데아\n",
        "- 목표, 제약, 결정변수, 불확실성(특이점)을 5~9줄\n",
        "\n",
        "### 프론티어(표)\n",
        "- 보수/균형/진보 3대안 표 1개 (열: 대안, 핵심수단, 기대효과, Trade-off, 재정설명)\n",
        "- Markdown 표로 작성\n",
        "\n",
        "### 대안 상세(3개)\n",
        "- 각 대안을 6~10줄: 핵심 레버 3개, 기대효과, 위험/완화, 실행 로드맵\n",
        "\n",
        "### 스위칭 룰(IF–THEN)\n",
        "- 3~7개 규칙, 각 1줄. 예) IF PG>25% THEN H+=10 AND clawback-=5\n",
        "\n",
        "### KPI/피드백\n",
        "- KPI 3~6개(정의+측정), 분기별 조정 의사코드 5~9줄 (```text 블록 사용)\n",
        "\n",
        "### 수식/제약\n",
        "- 반드시 ```math 블록\n",
        "- B = E_eff + ΔVAT(τ_vat) + ΔTop(τ_top) + clawback(T) - {Cash(H) + W_sub(W) + Training + Admin}\n",
        "- 제약: B≥0, Admin≤2%, EMTR≤τ*\n",
        "\"\"\")\n",
        "\n",
        "DELEUZE_USER_TPL = md(\"\"\"\n",
        "질문:\n",
        "{q}\n",
        "\n",
        "근거 텍스트(선택):\n",
        "{ctx}\n",
        "\n",
        "지시:\n",
        "- 위 6개 섹션을 반드시 모두 출력한다.\n",
        "- 프론티어는 마크다운 표, 수식은 ```math 블록으로 작성한다.\n",
        "- [END]는 쓰지 않는다.\n",
        "\"\"\")\n",
        "\n",
        "REQ_HEADS = [\"### 문제-이데아\",\"### 프론티어(표)\",\"### 대안 상세(3개)\",\"### 스위칭 룰\",\"### KPI/피드백\",\"### 수식/제약\"]\n",
        "\n",
        "def is_deleuze_structured(text: str) -> bool:\n",
        "    has_sections = all(h in text for h in REQ_HEADS)\n",
        "    has_table    = (\"|\" in text and \"---\" in text)\n",
        "    has_math     = \"```math\" in text\n",
        "    return has_sections and has_table and has_math\n",
        "\n",
        "def repair_deleuze(text, q, ctx, model, temperature, top_p):\n",
        "    if is_deleuze_structured(text):\n",
        "        return text\n",
        "    missing = [h for h in REQ_HEADS if h not in text]\n",
        "    sys = \"You are a strict editor. Fill ONLY the missing sections exactly as specified.\"\n",
        "    usr = md(f\"\"\"\n",
        "누락된 섹션: {\", \".join(missing)}\n",
        "질문: {q}\n",
        "근거: {ctx or \"없음\"}\n",
        "\n",
        "[초안 시작]\n",
        "{text}\n",
        "[초안 끝]\n",
        "\n",
        "규칙:\n",
        "- 기존 텍스트는 수정하지 말고, 누락된 섹션만 추가.\n",
        "- 프론티어는 마크다운 표, 수식은 ```math 블록.\n",
        "\"\"\")\n",
        "    fixed = llm_long(sys, usr, model, temperature, top_p, segment_tokens=1200, max_segments=4)\n",
        "    return fixed if is_deleuze_structured(fixed) else text\n"
      ],
      "metadata": {
        "id": "cvvznLO4Xv2_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Markdown 표 → DataFrame\n",
        "def parse_markdown_table(md_text: str) -> Optional[pd.DataFrame]:\n",
        "    lines = [ln.rstrip() for ln in md_text.splitlines()]\n",
        "    for i, ln in enumerate(lines):\n",
        "        if \"|\" in ln and re.search(r\"\\|\\s*-+\\s*\\|\", ln):\n",
        "            header_idx = i-1 if i>0 else None\n",
        "            if header_idx is None:\n",
        "                continue\n",
        "            block = []\n",
        "            j = header_idx\n",
        "            while j < len(lines) and \"|\" in lines[j]:\n",
        "                block.append(lines[j]); j += 1\n",
        "            hdr = [c.strip() for c in block[0].strip(\"|\").split(\"|\")]\n",
        "            body = []\n",
        "            for row in block[2:]:\n",
        "                cols = [c.strip() for c in row.strip(\"|\").split(\"|\")]\n",
        "                if len(cols) == len(hdr):\n",
        "                    body.append(cols)\n",
        "            if body:\n",
        "                return pd.DataFrame(body, columns=hdr)\n",
        "    return None\n",
        "\n",
        "# 옵션 라벨 표준화\n",
        "def _normalize_option_names(series: pd.Series) -> pd.Series:\n",
        "    def map_name(s: str) -> str:\n",
        "        t = str(s); tl = t.lower()\n",
        "        if any(k in t for k in [\"보수\",\"보수형\"]) or \"conservative\" in tl: return \"보수\"\n",
        "        if any(k in t for k in [\"균형\",\"중도\"])   or \"balanced\" in tl or \"moderate\" in tl: return \"균형\"\n",
        "        if any(k in t for k in [\"진보\",\"공격\",\"확대\",\"강화\"]) or \"progressive\" in tl or \"aggressive\" in tl: return \"진보\"\n",
        "        return t\n",
        "    return series.apply(map_name)\n",
        "\n",
        "# 텍스트 키워드 기반 점수\n",
        "_FISCAL_POS = [\"세수\",\"세입\",\"흑자\",\"절감\",\"지출 효율\",\"클로백\",\"재원\",\"기금\",\"균형재정\",\"건전성\"]\n",
        "_FISCAL_NEG = [\"적자\",\"지출 확대\",\"보조금\",\"부채\",\"감세\",\"재정 악화\",\"적자전환\",\"재정 부담\"]\n",
        "_EFFECT_POS = [\"효율\",\"효과\",\"성과\",\"감축\",\"달성\",\"목표 경로\",\"가격신호\",\"타게팅\",\"지표\",\"모니터링\",\"피드백\",\"정확\"]\n",
        "_EFFECT_NEG = [\"의존\",\"지연\",\"부작용\",\"비효율\",\"왜곡\",\"과소지원\",\"집행 지체\"]\n",
        "_NUM_PAT  = re.compile(r\"(\\d+(?:\\.\\d+)?)\\s*(%|톤|MW|GW|조원|억원|만원|배|p|퍼센트)\")\n",
        "\n",
        "def _keyword_score(text: str, pos_words: List[str], neg_words: List[str]) -> float:\n",
        "    s = str(text)\n",
        "    pos = sum(1 for w in pos_words if w in s)\n",
        "    neg = sum(1 for w in neg_words if w in s)\n",
        "    return float(pos - neg)\n",
        "\n",
        "def _magnitude_boost(text: str) -> float:\n",
        "    matches = list(_NUM_PAT.finditer(str(text)))\n",
        "    return min(5.0, 0.8 * len(matches))\n",
        "\n",
        "def _normalize_minmax(arr: np.ndarray) -> np.ndarray:\n",
        "    lo, hi = float(np.min(arr)), float(np.max(arr))\n",
        "    if hi - lo < 1e-8:\n",
        "        return np.full_like(arr, 50.0)\n",
        "    return 100.0 * (arr - lo) / (hi - lo)\n",
        "\n",
        "def frontier_to_numeric(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df2 = df.copy()\n",
        "    ren = {}\n",
        "    for c in df2.columns:\n",
        "        if \"대안\" in c: ren[c] = \"대안\"\n",
        "        if \"핵심\" in c: ren[c] = \"핵심수단\"\n",
        "        if \"기대효\" in c: ren[c] = \"기대효과\"\n",
        "        if \"Trade\" in c or \"trade\" in c.lower(): ren[c] = \"Trade-off\"\n",
        "        if any(k in c for k in [\"예산\",\"B\",\"재정\"]): ren[c] = \"재정설명\"\n",
        "    df2.rename(columns=ren, inplace=True)\n",
        "    if \"대안\" not in df2.columns:\n",
        "        df2.rename(columns={df2.columns[0]:\"대안\"}, inplace=True)\n",
        "\n",
        "    df2[\"대안\"] = _normalize_option_names(df2[\"대안\"])\n",
        "\n",
        "    def row_text(row):\n",
        "        cols = []\n",
        "        for k in [\"대안\",\"핵심수단\",\"기대효과\",\"Trade-off\",\"재정설명\"]:\n",
        "            if k in df2.columns: cols.append(str(row.get(k,\"\")))\n",
        "        return \" \".join(cols)\n",
        "\n",
        "    fiscal_raw, effect_raw = [], []\n",
        "    for _, row in df2.iterrows():\n",
        "        txt = row_text(row)\n",
        "        f = _keyword_score(txt, _FISCAL_POS, _FISCAL_NEG) + _magnitude_boost(txt)\n",
        "        e = _keyword_score(txt, _EFFECT_POS, _EFFECT_NEG) + _magnitude_boost(txt)\n",
        "        fiscal_raw.append(f); effect_raw.append(e)\n",
        "\n",
        "    fiscal_arr = _normalize_minmax(np.array(fiscal_raw, dtype=float))\n",
        "    effect_arr = _normalize_minmax(np.array(effect_raw, dtype=float))\n",
        "\n",
        "    df2[\"재정 기여 지수(텍스트 기반)\"] = np.round(fiscal_arr, 1)\n",
        "    df2[\"성과 지수(텍스트 기반)\"]   = np.round(effect_arr, 1)\n",
        "\n",
        "    # 파라미터 예시(핵심수단 텍스트 길이에 비례)\n",
        "    if \"핵심수단\" in df2.columns:\n",
        "        ln = df2[\"핵심수단\"].astype(str).str.len()\n",
        "        df2[\"param_세율/가격신호\"]   = (ln/100).clip(0, 1.0).round(2)\n",
        "        df2[\"param_정밀환급/클로백\"] = (ln/140).clip(0, 1.2).round(2)\n",
        "        df2[\"param_훈련/전환지원\"]   = (ln/60).clip(0, 6).round(2)\n",
        "    else:\n",
        "        n = len(df2)\n",
        "        df2[\"param_세율/가격신호\"]   = np.linspace(0.2, 0.8, n).round(2)\n",
        "        df2[\"param_정밀환급/클로백\"] = np.linspace(0.3, 0.9, n).round(2)\n",
        "        df2[\"param_훈련/전환지원\"]   = np.linspace(2, 6,   n).round(2)\n",
        "\n",
        "    # 종합점수(랭킹용): 성과(0.6)+재정(0.4)\n",
        "    df2[\"종합점수\"] = np.round(0.6*df2[\"성과 지수(텍스트 기반)\"] + 0.4*df2[\"재정 기여 지수(텍스트 기반)\"], 1)\n",
        "    return df2\n",
        "\n",
        "def build_plots(df_num: pd.DataFrame):\n",
        "    xname, yname = \"성과 지수(텍스트 기반)\", \"재정 기여 지수(텍스트 기반)\"\n",
        "\n",
        "    fig1 = go.Figure()\n",
        "    fig1.add_trace(go.Scatter(\n",
        "        x=df_num[xname], y=df_num[yname],\n",
        "        mode=\"markers+text\",\n",
        "        text=df_num[\"대안\"].astype(str),\n",
        "        textposition=\"top center\",\n",
        "        name=\"정책안\"\n",
        "    ))\n",
        "    fig1.update_layout(\n",
        "        title=\"프론티어 — 성과 vs 재정(표 텍스트 근거 정규화)\",\n",
        "        xaxis_title=f\"{xname} (↑좋음)\", yaxis_title=f\"{yname} (↑재정건전성 기여)\",\n",
        "        template=\"plotly_white\", height=360\n",
        "    )\n",
        "\n",
        "    fig2 = go.Figure()\n",
        "    param_cols = [c for c in df_num.columns if c.startswith(\"param_\")]\n",
        "    for col in param_cols:\n",
        "        fig2.add_trace(go.Bar(x=df_num[\"대안\"], y=df_num[col], name=col.replace(\"param_\",\"\")))\n",
        "    fig2.update_layout(title=\"핵심 파라미터 비교(텍스트 유도)\", barmode=\"group\",\n",
        "                       template=\"plotly_white\", height=360)\n",
        "\n",
        "    t = np.arange(1, 7)\n",
        "    base_eff = float(np.nanmean(df_num[xname].values)) if len(df_num) else 50.0\n",
        "    base_fsc = float(np.nanmean(df_num[yname].values)) if len(df_num) else 50.0\n",
        "    pg = (28 - 0.10*(base_eff-50) - 1.0*(t-1) + np.random.randn(len(t))*0.25).clip(12,30)\n",
        "    B  = (-0.2 + 0.02*(base_fsc-50) + 0.4*np.sin(t/1.2) + np.random.randn(len(t))*0.1).round(2)\n",
        "\n",
        "    fig3 = go.Figure()\n",
        "    fig3.add_trace(go.Scatter(x=t, y=pg, mode=\"lines+markers\", name=\"성과계열 KPI 예시\"))\n",
        "    fig3.add_trace(go.Scatter(x=t, y=B,  mode=\"lines+markers\", name=\"재정계열 KPI 예시\"))\n",
        "    fig3.update_layout(title=\"KPI 시뮬레이션(표 텍스트 기저선)\", xaxis_title=\"기간\",\n",
        "                       template=\"plotly_white\", height=360)\n",
        "    return fig1, fig2, fig3\n"
      ],
      "metadata": {
        "id": "IO5mNXrMXv0u"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def structure_score(text: str) -> float:\n",
        "    h = sum(1 for s in REQ_HEADS if s in text) / len(REQ_HEADS)\n",
        "    has_table = 1.0 if (\"|\" in text and \"---\" in text) else 0.0\n",
        "    has_math  = 1.0 if \"```math\" in text else 0.0\n",
        "    return round(0.6*h + 0.2*has_table + 0.2*has_math, 3)\n",
        "\n",
        "def novelty_score(candidate: str, baseline: str) -> float:\n",
        "    vec = TfidfVectorizer(min_df=1, max_df=0.95, ngram_range=(1,2))\n",
        "    X = vec.fit_transform([candidate, baseline])\n",
        "    sim = float(cosine_similarity(X[0], X[1])[0,0])\n",
        "    return round(max(0.0, 1.0 - sim), 3)\n",
        "\n",
        "def length_score(text: str) -> float:\n",
        "    n = len(text)\n",
        "    if n < 400:  return 0.4\n",
        "    if n > 8000: return 0.7\n",
        "    x = (min(2500, n) - 400) / (2500-400)\n",
        "    return round(0.6 + 0.4*max(0.0, min(1.0, x)), 3)\n",
        "\n",
        "@dataclass\n",
        "class RunConfig:\n",
        "    model_id: str\n",
        "    temperature: float\n",
        "    top_p: float\n",
        "\n",
        "def baseline_answer(q, model, temperature, top_p) -> str:\n",
        "    sys = BASELINE_SYSTEM\n",
        "    usr = BASELINE_USER_TPL.format(q=q)\n",
        "    return llm_long(sys, usr, model, temperature, top_p,\n",
        "                    segment_tokens=LONG_SEGMENT_TOKENS, max_segments=LONG_MAX_SEGMENTS)\n",
        "\n",
        "def deleuze_answer(q, ctx, model, temperature, top_p) -> str:\n",
        "    sys = DELEUZE_SYSTEM\n",
        "    usr = DELEUZE_USER_TPL.format(q=q, ctx=ctx or \"없음\")\n",
        "    return llm_long(sys, usr, model, temperature, top_p,\n",
        "                    segment_tokens=LONG_SEGMENT_TOKENS, max_segments=LONG_MAX_SEGMENTS)\n",
        "\n",
        "def run_pipeline(q: str, ctx: str, cfg: RunConfig):\n",
        "    t0 = time.time()\n",
        "\n",
        "    # A) 순정 GPT (문단형)\n",
        "    baseline = baseline_answer(q, cfg.model_id, cfg.temperature, cfg.top_p)\n",
        "\n",
        "    # B) 들뢰즈 오퍼레이터(6섹션 강제) + 누락 보정\n",
        "    cand = deleuze_answer(q, ctx, cfg.model_id, cfg.temperature, cfg.top_p)\n",
        "    cand = repair_deleuze(cand, q, ctx, cfg.model_id, cfg.temperature, cfg.top_p)\n",
        "\n",
        "    # 프론티어 표 파싱 → 텍스트 지수화 → 그래프\n",
        "    df_front = parse_markdown_table(cand)\n",
        "    auto_ok = df_front is not None\n",
        "    if not auto_ok:\n",
        "        # 표가 없을 경우 최소 폴백(임의 수치 없이 텍스트 구조만)\n",
        "        df_front = pd.DataFrame({\n",
        "            \"대안\":     [\"보수\",\"균형\",\"진보\"],\n",
        "            \"핵심수단\": [\"세율 완만·정밀 환급·집행 효율\", \"가격신호+환급 균형·중간 강도\", \"강한 가격신호·대규모 전환지원\"],\n",
        "            \"기대효과\": [\"점진 개선\", \"목표 경로 근접\", \"고강도 성과\"],\n",
        "            \"Trade-off\":[\"속도·불평등 리스크 낮음\", \"중간 부담/성과\", \"재정·수용성 부담\"],\n",
        "            \"재정설명\":[\"재정건전성 우선\", \"균형적 재원 구성\", \"전환지원 중심 재원\"]\n",
        "        })\n",
        "    df_num = frontier_to_numeric(df_front)\n",
        "    fig1, fig2, fig3 = build_plots(df_num)\n",
        "\n",
        "    # 랭킹 테이블\n",
        "    rank_df = df_num[[\"대안\",\"성과 지수(텍스트 기반)\",\"재정 기여 지수(텍스트 기반)\",\"종합점수\"]].copy()\n",
        "    rank_df = rank_df.sort_values(\"종합점수\", ascending=False).reset_index(drop=True)\n",
        "    rank_df.index = rank_df.index + 1\n",
        "    rank_df = rank_df.rename_axis(\"rank\").reset_index()\n",
        "\n",
        "    # 간단 점수(전부 오픈소스)\n",
        "    s_struct = structure_score(cand)\n",
        "    s_novel  = novelty_score(cand, baseline)\n",
        "    s_len    = length_score(cand)\n",
        "    final_score = round(0.55*s_struct + 0.35*s_novel + 0.10*s_len, 3)\n",
        "\n",
        "    meta = {\n",
        "        \"runtime_sec\": round(time.time()-t0,2),\n",
        "        \"frontier_auto\": bool(auto_ok),\n",
        "        \"oss_modules\": [\"gradio\",\"plotly\",\"pandas\",\"scikit-learn\",\"regex\"],\n",
        "        \"scores\": {\"structure\": s_struct, \"novelty\": s_novel, \"length\": s_len, \"final\": final_score}\n",
        "    }\n",
        "    return baseline, cand, fig1, fig2, fig3, rank_df, meta\n"
      ],
      "metadata": {
        "id": "mKFNG-M8XvyW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "try:\n",
        "    gr.close_all()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "PORT = find_free_port()\n",
        "\n",
        "with gr.Blocks(title=\"A: 순정 GPT vs B: GPT+들뢰즈 — 구조·프론티어·스위칭·KPI\") as demo:\n",
        "    gr.Markdown(md(\"\"\"\n",
        "    ## 🔍 비교 데모 — **A: 순정 GPT(문단)** vs **B: GPT+들뢰즈(표·수식·그래프·랭킹)**\n",
        "    - 생성은 OpenAI API. 표 파싱/지수화/그래프/랭킹/평가는 **모두 오픈소스**로 수행합니다.\n",
        "    - 프론티어 축(성과/재정)은 **표의 텍스트 근거(키워드·숫자)** 를 정규화해 산출합니다(임의 수치 사용 없음).\n",
        "    \"\"\"))\n",
        "\n",
        "    with gr.Accordion(\"🔑 OpenAI API 키\", open=True):\n",
        "        key = gr.Textbox(type=\"password\", placeholder=\"sk-...\")\n",
        "        out = gr.Markdown()\n",
        "        def set_key(k):\n",
        "            os.environ[\"OPENAI_API_KEY\"]=k.strip()\n",
        "            return \"✅ 저장 완료\"\n",
        "        gr.Button(\"키 저장\").click(set_key, inputs=[key], outputs=[out])\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            q   = gr.Textbox(label=\"질문\", lines=6,\n",
        "                             placeholder=\"예) 탄소세와 전환지원으로 2030년 –40% 감축 설계…\")\n",
        "            ctx = gr.Textbox(label=\"근거 텍스트(선택)\", lines=6,\n",
        "                             placeholder=\"프론티어 표 컬럼, KPI, 임계치(θ), 조정폭(δ) 등 힌트를 넣으면 구조가 더 정밀해집니다.\")\n",
        "            with gr.Accordion(\"고급설정\", open=False):\n",
        "                model = gr.Textbox(value=\"gpt-4o-mini\", label=\"OpenAI Model ID\")\n",
        "                temp  = gr.Slider(0.0, 1.2, value=0.7, step=0.05, label=\"temperature\")\n",
        "                top_p = gr.Slider(0.1, 1.0, value=0.9, step=0.05, label=\"top_p\")\n",
        "            run_btn = gr.Button(\"실행\", variant=\"primary\")\n",
        "            meta_box = gr.Markdown()\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            base_box = gr.Markdown()  # 문단형 가독성 위해 Markdown 사용\n",
        "        with gr.Column(scale=2):\n",
        "            deleuze_box = gr.Markdown()  # 표/수식 렌더링을 위해 Markdown\n",
        "            with gr.Row():\n",
        "                fig1 = gr.Plot(label=\"프론티어 — 성과 vs 재정(표 텍스트 근거)\")\n",
        "                fig2 = gr.Plot(label=\"핵심 파라미터 비교(텍스트 유도)\")\n",
        "            fig3 = gr.Plot(label=\"KPI 시뮬레이션(표 텍스트 기저선)\")\n",
        "            rank_tbl = gr.Dataframe(label=\"대안 랭킹(텍스트 기반 지수)\", wrap=True, interactive=False)\n",
        "\n",
        "    def on_run(question, context, model_id, temperature, top_p):\n",
        "        cfg = RunConfig(model_id=model_id, temperature=float(temperature), top_p=float(top_p))\n",
        "        try:\n",
        "            b, d, f1, f2, f3, rank_df, meta = run_pipeline(question, context, cfg)\n",
        "            sc = meta[\"scores\"]\n",
        "            chip = (\n",
        "                f\"**Runtime**: {meta['runtime_sec']}s · \"\n",
        "                f\"**Frontier**: {'표 자동파싱✅' if meta['frontier_auto'] else '표 부재→텍스트 폴백⚠️'}  \\n\"\n",
        "                f\"**축 정의**: 성과/재정 지수는 **표 텍스트 근거**로 정규화 산출  \\n\"\n",
        "                f\"**OSS**: gradio, plotly, pandas, scikit-learn, regex  \\n\"\n",
        "                f\"**(참고)** 구조 {sc['structure']}, 창의 {sc['novelty']}, 길이 {sc['length']}, 최종 {sc['final']}\"\n",
        "            )\n",
        "            # A/B를 Markdown으로 노출 (A는 문단, B는 섹션/표/수식)\n",
        "            base_md    = md(b)\n",
        "            deleuze_md = md(d)\n",
        "            return base_md, deleuze_md, f1, f2, f3, rank_df, chip\n",
        "        except Exception as e:\n",
        "            tb = \"```\\n\"+traceback.format_exc()+\"\\n```\"\n",
        "            return \"❌ 오류\", f\"❌ 오류: {e}\\n{tb}\", go.Figure(), go.Figure(), go.Figure(), pd.DataFrame(), \"\"\n",
        "\n",
        "    run_btn.click(on_run, inputs=[q, ctx, model, temp, top_p],\n",
        "                  outputs=[base_box, deleuze_box, fig1, fig2, fig3, rank_tbl, meta_box])\n",
        "\n",
        "demo.queue(max_size=32).launch(share=True, server_name=\"0.0.0.0\", server_port=PORT, show_error=True)\n",
        "print(\"🔗 Port:\", PORT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "RJzYYO2QXvv1",
        "outputId": "7a70c3e1-3e36-4e90-c360-213c222942cc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/analytics.py:106: UserWarning:\n",
            "\n",
            "IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on public URL: https://e5ed36aa772b4aa1d8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e5ed36aa772b4aa1d8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Port: 7862\n"
          ]
        }
      ]
    }
  ]
}